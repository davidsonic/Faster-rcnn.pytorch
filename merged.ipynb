{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "import proposal_func\n",
    "import detection_target_fixed\n",
    "from classifier_fixed import fpn_classifiler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilsV3 import shapeData as dataSet\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "dataset = dataSet([64,64], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNorm(KL.BatchNormalization):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super(self.__class__, self).call(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def building_block(filters, block):\n",
    "    if block !=0 :\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4*filters, (1,1))(y)\n",
    "        y = BatchNorm(axis=3)(y)\n",
    "        \n",
    "        if block == 0:\n",
    "            shorcut = KL.Conv2D(4*filters, (1,1), strides=stride)(x)\n",
    "            shorcut = BatchNorm(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resNet_featureExtractor(inputs):\n",
    "    x = KL.Conv2D(64, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNorm(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    filters = 64\n",
    "    blocks = [6, 6, 6]\n",
    "    for i, block_num in enumerate(blocks):\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters *= 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rpn_net(inputs, k):\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    rpn_class = KL.Conv2D(2*k, (1,1))(shared_map)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,4]))(y)\n",
    "    return rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    ## rpn_match (None, 576, 1)\n",
    "    ## rpn_class_logits (None, 576, 2)\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)     ### prediction\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   ### target\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class, output=rpn_class_logits, from_logits=True)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "def batch_back(x, counts, num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.equal(rpn_match, 1))\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1)\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, 20)\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    return loss\n",
    "\n",
    "def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):\n",
    "\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    target_bbox = K.reshape(target_bbox, (-1, 4))\n",
    "    pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))\n",
    "\n",
    "    positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "    positive_roi_class_ids = tf.cast(\n",
    "        tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "    indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "    target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "    pred_bbox = tf.gather_nd(pred_bbox, indices)\n",
    "\n",
    "    loss = K.switch(tf.size(target_bbox) > 0,\n",
    "                    smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    loss = K.reshape(loss, [1, 1])\n",
    "    return loss\n",
    "\n",
    "def mrcnn_class_loss_graph(target_class_ids, pred_class_logits,\n",
    "                           active_class_ids):\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "    print(\"active_class_ids\", active_class_ids)\n",
    "    # Find predictions of classes that are not in the dataset.\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    # TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "    #       images in a batch have the same active_class_ids\n",
    "    pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    pred_active = tf.cast(pred_active, tf.float32)\n",
    "    print(\"loss\", loss)\n",
    "    print(\"pred_active\", pred_active)\n",
    "    loss = loss * pred_active\n",
    "\n",
    "    # Computer loss mean. Use only predictions that contribute\n",
    "    # to the loss to get a correct mean.\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mrcnn_class_loss_graphV2(target_class_ids, pred_class_logits,\n",
    "                           active_class_ids, batch_size=20):\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "    #print(\"target_class_ids\",target_class_ids.shape)\n",
    "    \n",
    "    #print(\"pred_class_logits\",pred_class_logits.shape)\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    #print(\"pred_class_ids2\",pred_class_ids.shape)\n",
    "\n",
    "    #print(\"active_class_ids\",active_class_ids[0].shape)\n",
    "    #pred_active = tf.zeros((batch_size, tf.shape(target_class_ids)[1]))\n",
    "    pred_active = utils.batch_slice([active_class_ids, pred_class_ids], lambda x,y:tf.gather(x,y), batch_size)\n",
    "    #for i in range(batch_size):\n",
    "    #    pred_active[i] = tf.gather(active_class_ids[i], pred_class_ids[i])\n",
    "        #pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "    #print(\"pred_active\",pred_active.shape)\n",
    "\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    pred_active = tf.cast(pred_active, tf.float32)\n",
    "\n",
    "    loss = loss * pred_active\n",
    "\n",
    "\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#target_class_ids = test_out[5]\n",
    "#mrcnn_class_logits = test_out[8]\n",
    "\n",
    "#input_active_ids_ = test_data[0][3]\n",
    "\n",
    "\n",
    "#loss = mrcnn_class_loss_graphV2(target_class_ids, mrcnn_class_logits, input_active_ids_, 20)\n",
    "\n",
    "#sess.run(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.engine as KE\n",
    "\n",
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def refine_detections(rois, probs, deltas):\n",
    "    argMax_probs = tf.argmax(probs, axis=1)\n",
    "    max_probs = tf.reduce_max(probs, axis=1)\n",
    "    keep_idxs = tf.where(max_probs > 0.5)[:,0]\n",
    "    idx_y = tf.cast(np.arange(16), tf.int32)\n",
    "    idx_x = tf.cast(argMax_probs, tf.int32)\n",
    "    idxs = tf.stack([idx_y, idx_x],axis=1)\n",
    "    deltas_keep = tf.gather_nd(deltas, idxs)\n",
    "    refined_rois = anchor_refinement(tf.cast(rois, tf.float32),\n",
    "                                 tf.cast(deltas_keep * config.RPN_BBOX_STD_DEV, tf.float32))\n",
    "    rois_ready = tf.gather(refined_rois, keep_idxs)\n",
    "    class_ids = tf.gather(argMax_probs, keep_idxs)\n",
    "    class_ids = tf.to_float(class_ids)[..., tf.newaxis]\n",
    "    detections = tf.concat([rois_ready, class_ids], axis=1)\n",
    "    gap = tf.maximum(16 - tf.shape(detections)[0],0)\n",
    "    detections = tf.pad(detections, [(0, gap), (0, 0)], \"CONSTANT\")\n",
    "    return detections\n",
    "### NMS\n",
    "\n",
    "class DetectionLayer(KE.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DetectionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        rois = inputs[0]\n",
    "        probs = inputs[1]\n",
    "        deltas = inputs[2]\n",
    "        \n",
    "        detections_batch = utils.batch_slice(\n",
    "            [rois, probs, deltas],\n",
    "            lambda x, y, z: refine_detections(x, y, z),\n",
    "            20)\n",
    "        \n",
    "        #return tf.reshape(\n",
    "        #    detections_batch,\n",
    "        #    [16, 8, -1])\n",
    "        return detections_batch\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 8, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training inference \n",
    "\n",
    "## RPN   all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fasterRCNN():\n",
    "    def __init__(self, mode, subnet, config):\n",
    "        assert mode in [\"training\", \"inference\"]\n",
    "        self.mode = mode\n",
    "        self.config = config\n",
    "        self.subnet = subnet\n",
    "        self.keras_model = self.build(mode=mode, subnet=subnet, config=config)\n",
    "    \n",
    "    def build(self, mode, subnet, config):\n",
    "        \n",
    "        assert mode in [\"training\", \"inference\"]\n",
    "        input_image = KL.Input(shape=[64,64,3], dtype=tf.float32)\n",
    "        input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)\n",
    "        input_class_ids = KL.Input(shape=[None],dtype=tf.int32)\n",
    "        input_active_ids = KL.Input(shape=[4,], dtype=tf.int32)\n",
    "        input_rpn_match = KL.Input(shape=[None, 1], dtype=tf.int32)\n",
    "        input_rpn_bbox = KL.Input(shape=[None, 4], dtype=tf.float32)\n",
    "        \n",
    "        h, w = config.image_size[: 2]\n",
    "        image_scale = K.cast(K.stack([h,w,h,w], axis=0), tf.float32)\n",
    "        gt_bboxes = KL.Lambda(lambda x: x / image_scale)(input_bboxes)\n",
    "\n",
    "        feature_map = resNet_featureExtractor(input_image)\n",
    "        rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, 9)\n",
    "\n",
    "        anchors = utils.anchor_gen(featureMap_size=[8, 8], ratios=config.ratios, scales=config.scales,\\\n",
    "                                   rpn_stride=config.rpn_stride,anchor_stride=config.anchor_stride)\n",
    "\n",
    "        proposals = proposal_func.proposal(proposal_count=16, nms_thresh=0.7, anchors=anchors, \\\n",
    "                                           batch_size=20, config=config)([rpn_prob, rpn_bbox])\n",
    "        if mode == \"training\":\n",
    "            target_rois, target_class_ids, target_delta, target_bboxes = detection_target_fixed.DetectionTarget(config=config, \\\n",
    "                              name=\"proposal_target\")([proposals,input_class_ids,gt_bboxes])\n",
    "            denomrlaize_rois = KL.Lambda(lambda x:8.0*x, name=\"denormalized_rois\")(target_rois)\n",
    "            mrcnn_class_logits, mrcnn_class, mrcnn_bbox = fpn_classifiler(feature_map, denomrlaize_rois, 20, 21, 7, 4)\n",
    "            \n",
    "            loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")([input_rpn_match, rpn_class])\n",
    "\n",
    "            loss_rpn_bbox = KL.Lambda(lambda x: rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")([input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "\n",
    "            bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=\"bbox_loss\")(\n",
    "                                                [target_delta, target_class_ids, mrcnn_bbox])\n",
    "            class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graphV2(*x), name=\"mrcnn_class_loss\")(\n",
    "                                        [target_class_ids, mrcnn_class_logits, input_active_ids])\n",
    "            \n",
    "            if subnet == \"rpn\":\n",
    "            \n",
    "                model = Model([input_image, input_bboxes, input_class_ids, input_active_ids, input_rpn_match, input_rpn_bbox],\n",
    "                              [feature_map, rpn_class, rpn_prob, rpn_bbox, proposals, target_rois, denomrlaize_rois,target_class_ids, target_delta, target_bboxes, \\\n",
    "                               loss_rpn_match, loss_rpn_bbox])\n",
    "            elif subnet == \"all\":\n",
    "                model = Model([input_image, input_bboxes, input_class_ids, input_active_ids, input_rpn_match, input_rpn_bbox],\n",
    "                [feature_map, rpn_class, rpn_prob, rpn_bbox, proposals, target_rois, denomrlaize_rois,target_class_ids, target_delta, target_bboxes, \\\n",
    "                 mrcnn_class_logits, mrcnn_class, mrcnn_bbox, loss_rpn_match, loss_rpn_bbox, bbox_loss, class_loss])\n",
    "            \n",
    "        if mode == \"inference\":\n",
    "            denomrlaize_proposals = KL.Lambda(lambda x:8.0*x, name=\"denormalized_proposals\")(proposals)\n",
    "            mrcnn_class_logits, mrcnn_class, mrcnn_bbox = fpn_classifiler(feature_map, denomrlaize_proposals, 20, 16, 7, 4)\n",
    "            detections = DetectionLayer()([proposals, mrcnn_class, mrcnn_bbox])\n",
    "            \n",
    "            model = Model([input_image],[detections])\n",
    "            \n",
    "        return model\n",
    "                \n",
    "    def compile_(self):\n",
    "        loss_lay1 = self.keras_model.get_layer(\"loss_rpn_match\").output\n",
    "        loss_lay2 = self.keras_model.get_layer(\"loss_rpn_bbox\").output\n",
    "        if self.subnet == \"all\":\n",
    "            loss_lay3 = self.keras_model.get_layer(\"bbox_loss\").output\n",
    "            loss_lay4 = self.keras_model.get_layer(\"mrcnn_class_loss\").output\n",
    "\n",
    "        self.keras_model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "        self.keras_model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "        if self.subnet == \"all\":\n",
    "            self.keras_model.add_loss(tf.reduce_mean(loss_lay3))\n",
    "            self.keras_model.add_loss(tf.reduce_mean(loss_lay4))\n",
    "\n",
    "        self.keras_model.compile(loss=[None]*len(self.keras_model.output), optimizer=keras.optimizers.SGD(lr=0.00005, momentum=0.9))\n",
    "\n",
    "        self.keras_model.metrics_names.append(\"loss_rpn_match\")\n",
    "        self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keep_dims=True))\n",
    "\n",
    "        self.keras_model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "        self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keep_dims=True))\n",
    "\n",
    "        if self.subnet == \"all\":\n",
    "            self.keras_model.metrics_names.append(\"bbox_loss\")\n",
    "            self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay3, keep_dims=True))\n",
    "\n",
    "            self.keras_model.metrics_names.append(\"mrcnn_class_loss\")\n",
    "            self.keras_model.metrics_tensors.append(tf.reduce_mean(loss_lay4, keep_dims=True))\n",
    "        \n",
    "    def training(self, dataGen):\n",
    "        self.compile_()\n",
    "        his = self.keras_model.fit_generator(dataGen, steps_per_epoch=20, epochs=100)\n",
    "    def inference(self, testdata):\n",
    "        assert self.mode == \"inference\"\n",
    "        out = self.keras_model.predict(testdata)\n",
    "        return out\n",
    "    \n",
    "    def save_weights(self, weights_path):\n",
    "        self.keras_model.save_weights(weights_path)\n",
    "        \n",
    "    def load_weights(self, weights_path):\n",
    "        from keras.engine import topology\n",
    "        import h5py\n",
    "        f = h5py.File(weights_path)\n",
    "        layers = self.keras_model.layers\n",
    "        topology.load_weights_from_hdf5_group_by_name(f, layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = fasterRCNN(mode=\"training\", subnet=\"all\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"test0910_1200_all_V2.h5\")\n",
    "#model.load_weights(\"test0909.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_Gen(dataset, num_batch, batch_size, config):\n",
    "    for _ in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        active_ids = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, active_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "            active_ids.append(active_id)\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        active_ids = np.concatenate(active_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        yield [images, bboxes, class_ids, active_ids, rpn_matchs, rpn_bboxes],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataGen = data_Gen(dataset, 35000, 20, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 22s 1s/step - loss: 0.6564 - loss_rpn_match: 0.0232 - loss_rpn_bbox: 0.1912 - bbox_loss: 0.1955 - mrcnn_class_loss: 0.2465\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.6646 - loss_rpn_match: 0.0239 - loss_rpn_bbox: 0.1990 - bbox_loss: 0.1996 - mrcnn_class_loss: 0.2421\n",
      "Epoch 3/100\n",
      " 6/20 [========>.....................] - ETA: 3s - loss: 0.7348 - loss_rpn_match: 0.0234 - loss_rpn_bbox: 0.2406 - bbox_loss: 0.2275 - mrcnn_class_loss: 0.2433"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8327b395da37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-cc1df0427005>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, dataGen)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mhis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.training(dataGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(\"rpn_1103_aaa.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights(\"test0908.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = next(dataGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model.inference(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFiCAYAAAAna2l5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5afd43080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "ix = random.sample(range(20), 1)[0]\n",
    "\n",
    "image = test_data[0][0][ix]\n",
    "\n",
    "boxes_result = out[ix][:,:4] * 64\n",
    "id_result = out[ix][:,4]\n",
    "\n",
    "plt.imshow(image)\n",
    "Axs = plt.gca()\n",
    "\n",
    "pos_idxs = np.where(id_result > 0)[0]\n",
    "\n",
    "for i in range(pos_idxs.shape[0]):\n",
    "    id_ = pos_idxs[i]\n",
    "    box = boxes_result[id_]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], \n",
    "                           edgecolor=\"r\", facecolor=\"none\")\n",
    "    Axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pos_idxs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 5)\n",
      "(16, 5)\n",
      "(16, 5)\n"
     ]
    }
   ],
   "source": [
    "#rpn_class, rpn_prob, rpn_bbox, proposals, mrcnn_class_logits, mrcnn_class, mrcnn_bbox\n",
    "\n",
    "proposals_model = out[3]\n",
    "probs = out[5]\n",
    "deltas_infe = out[-1]\n",
    "\n",
    "print(proposals_model.shape)\n",
    "print(probs.shape)\n",
    "print(deltas_infe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid reduction dimension 1 for input with 1 dimensions. for 'Max' (op: 'Max') with input shapes: [5], [] and with computed input tensors: input[1] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension 1 for input with 1 dimensions. for 'Max' (op: 'Max') with input shapes: [5], [] and with computed input tensors: input[1] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0312be4d4a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdetections_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefine_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-0312be4d4a03>\u001b[0m in \u001b[0;36mrefine_detections\u001b[0;34m(rois, probs, deltas)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrefine_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margMax_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmax_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_probs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mkeep_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_probs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_max\u001b[0;34m(input_tensor, axis, keep_dims, name, reduction_indices)\u001b[0m\n\u001b[1;32m   1491\u001b[0m       \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_max\u001b[0;34m(input, reduction_indices, keep_dims, name)\u001b[0m\n\u001b[1;32m   1314\u001b[0m   result = _op_def_lib.apply_op(\"Max\", input=input,\n\u001b[1;32m   1315\u001b[0m                                 \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                                 keep_dims=keep_dims, name=name)\n\u001b[0m\u001b[1;32m   1317\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jon-liu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid reduction dimension 1 for input with 1 dimensions. for 'Max' (op: 'Max') with input shapes: [5], [] and with computed input tensors: input[1] = <1>."
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "ix = random.sample(range(20), 1)[0]\n",
    "images = test_data[0][0]\n",
    "image_ = images[ix]\n",
    "rois_ = proposals_model[ix]\n",
    "probs_ = probs[ix]\n",
    "deltas = deltas_infe[ix]\n",
    "\n",
    "\n",
    "def refine_detections(rois, probs, deltas):\n",
    "    argMax_probs = tf.argmax(probs, axis=1)\n",
    "    max_probs = tf.reduce_max(probs, axis=1)\n",
    "    print(\"max_probs\",sess.run(max_probs))\n",
    "    keep_idxs = tf.where(max_probs > 0.9)[:,0]\n",
    "    print(\"keep_idxs\",sess.run(keep_idxs))\n",
    "    idx_y = tf.cast(np.arange(16), tf.int32)\n",
    "    idx_x = tf.cast(argMax_probs, tf.int32)\n",
    "    idxs = tf.stack([idx_y, idx_x],axis=1)\n",
    "    deltas_keep = tf.gather_nd(deltas, idxs)\n",
    "    refined_rois = anchor_refinement(tf.cast(rois, tf.float32),\n",
    "                                 tf.cast(deltas_keep * config.RPN_BBOX_STD_DEV, tf.float32))\n",
    "    rois_ready = tf.gather(refined_rois, keep_idxs)\n",
    "    class_ids = tf.gather(argMax_probs, keep_idxs)\n",
    "    class_ids = tf.to_float(class_ids)[..., tf.newaxis]\n",
    "    detections = tf.concat([rois_ready, class_ids], axis=1)\n",
    "    gap = tf.maximum(8 - tf.shape(detections)[0],0)\n",
    "    detections = tf.pad(detections, [(0, gap), (0, 0)], \"CONSTANT\")\n",
    "    return detections\n",
    "\n",
    "detections_ = refine_detections(rois_, probs_, deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.89029557  0.89029557  0.77638763  0.74135059  0.98679578  0.99999881\n",
      "  0.99976593  0.54665428  0.89029557  0.99998927  0.98679578  0.99999881\n",
      "  0.99999177  0.99072623  0.99977356  0.99998617]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_probs = tf.reduce_max(probs_, axis=1)\n",
    "keep_idxs = tf.where(max_probs > 0.1)[:,0]\n",
    "print(sess.run(max_probs))\n",
    "sess.run(keep_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38540334,  0.62380558,  0.47496814,  0.70226341,  0.        ],\n",
       "       [ 0.65099984,  0.66500866,  0.75817555,  0.81201458,  0.        ],\n",
       "       [ 0.53934753,  0.74602336,  0.66800845,  0.82128531,  0.        ],\n",
       "       [ 0.60793793,  0.73478651,  0.76914346,  0.86544669,  0.        ],\n",
       "       [ 0.42722288,  0.59603786,  0.50535369,  0.66018021,  0.        ],\n",
       "       [ 0.671525  ,  0.68077636,  0.74297273,  0.77323449,  0.        ],\n",
       "       [ 0.57454634,  0.66104072,  0.65333462,  0.7326414 ,  0.        ],\n",
       "       [ 0.35690573,  0.56173325,  0.47147647,  0.67399359,  0.        ],\n",
       "       [ 0.6614421 ,  0.7179721 ,  0.76942509,  0.80553383,  0.        ],\n",
       "       [ 0.68863016,  0.56296659,  0.7816506 ,  0.72742558,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(detections_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proposal_ = proposals_model[ix] *64\n",
    "image_ = images[ix]\n",
    "probs_ = probs[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 0 0 0 0 2 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFiCAYAAAAna2l5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ab44f5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "print(np.argmax(probs_, axis=1))\n",
    "\n",
    "plt.imshow(image_)\n",
    "Axs = plt.gca()\n",
    "\n",
    "for i in range(proposal_.shape[0]):\n",
    "    box = proposal_[i]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], \n",
    "                           edgecolor=\"r\", facecolor=\"none\")\n",
    "    Axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_infe = out[-1][ix]\n",
    "deltas_infe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 16, 4, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ixs = np.argmax(probs_, axis=1)\n",
    "\n",
    "deltas = deltas_infe[np.arange(16), ixs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refined_rois = anchor_refinement(tf.cast(proposal_ / 64, tf.float32),\n",
    "                                 tf.cast(deltas * config.RPN_BBOX_STD_DEV, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refined_rois_ = sess.run(refined_rois) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_ixs = np.where(ixs > 0.4)[0]\n",
    "\n",
    "positive_ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFiCAYAAAAna2l5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ab2c0da58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_)\n",
    "Axs = plt.gca()\n",
    "\n",
    "for i in range(positive_ixs.shape[0]):\n",
    "    box = refined_rois_[positive_ixs[i]]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], \n",
    "                           edgecolor=\"b\", facecolor=\"none\")\n",
    "    Axs.add_patch(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
